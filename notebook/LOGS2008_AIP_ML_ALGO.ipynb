{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa56bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "# Imported Libraries\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Classifier Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import collections\n",
    "\n",
    "\n",
    "# Other Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff95f918",
   "metadata": {},
   "source": [
    "### Model Definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b4497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression \n",
    "def logistic_regression():\n",
    "    log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "\n",
    "    grid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params)\n",
    "    grid_log_reg.fit(X_train, y_train)\n",
    "\n",
    "    # We automatically get the logistic regression with the best parameters.\n",
    "    log_reg = grid_log_reg.best_estimator_\n",
    "    return log_reg\n",
    "\n",
    "\n",
    "\n",
    "# KNN Classifier\n",
    "def knn():    \n",
    "    knears_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "    grid_knears = GridSearchCV(KNeighborsClassifier(), knears_params)\n",
    "    grid_knears.fit(X_train, y_train)\n",
    "    # KNears best estimator\n",
    "    knears_neighbors = grid_knears.best_estimator_\n",
    "    return knears_neighbors\n",
    "\n",
    "\n",
    "\n",
    "# Support Vector Classifier\n",
    "def svc():\n",
    "    svc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\n",
    "    grid_svc = GridSearchCV(SVC(), svc_params)\n",
    "    grid_svc.fit(X_train, y_train)\n",
    "\n",
    "    # SVC best estimator\n",
    "    svc = grid_svc.best_estimator_\n",
    "    return svc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def decision_tree():\n",
    "    # DecisionTree Classifier\n",
    "    tree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n",
    "                  \"min_samples_leaf\": list(range(5,7,1))}\n",
    "    grid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params)\n",
    "    grid_tree.fit(X_train, y_train)\n",
    "\n",
    "    # tree best estimator\n",
    "    tree_clf = grid_tree.best_estimator_\n",
    "    return tree_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a321607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"LogisiticRegression\": logistic_regression(),\n",
    "    \"KNearest\": knn(),\n",
    "    \"Support Vector Classifier\": svc(),\n",
    "    \"DecisionTreeClassifier\": decision_tree()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f56ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78d0515c",
   "metadata": {},
   "source": [
    "### Model Evalution:\n",
    "\n",
    "#### Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e43d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# Defining number of columns\n",
    "n_cols, n_models = 3, len(classifiers)\n",
    "n_rows = math.ceil(n_models/n_cols)\n",
    "\n",
    "fig, ax = plt.subplots(n_rows, n_cols,figsize=(21, 7*n_rows))\n",
    "\n",
    "i, j = 0, 0\n",
    "for model in classifiers:\n",
    "    y_pred = classifiers[model].predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, ax=ax[i][j], annot=True, cmap=plt.cm.copper)\n",
    "    ax[i, j].set_title(model+\" \\n Confusion Matrix\", fontsize=14)\n",
    "    ax[i, j].set_xticklabels(['', ''], fontsize=14, rotation=90)\n",
    "    ax[i, j].set_yticklabels(['', ''], fontsize=14, rotation=360)\n",
    "    \n",
    "    if j==n_cols: j, i = 0, i+1\n",
    "    else: j+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23defa33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8601446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e76d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a79f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Defining number of columns\n",
    "n_cols = 3\n",
    "\n",
    "\n",
    "# Logistic Regression fitted using SMOTE technique\n",
    "y_pred_log_reg = log_reg_sm.predict(X_test)\n",
    "\n",
    "# Other models fitted with UnderSampling\n",
    "y_pred_knear = knears_neighbors.predict(X_test)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "\n",
    "\n",
    "log_reg_cf = confusion_matrix(y_test, y_pred_log_reg)\n",
    "kneighbors_cf = confusion_matrix(y_test, y_pred_knear)\n",
    "svc_cf = confusion_matrix(y_test, y_pred_svc)\n",
    "tree_cf = confusion_matrix(y_test, y_pred_tree)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2,figsize=(21, 7*n_rows))\n",
    "\n",
    "\n",
    "sns.heatmap(log_reg_cf, ax=ax[0][0], annot=True, cmap=plt.cm.copper)\n",
    "ax[0, 0].set_title(\"Logistic Regression \\n Confusion Matrix\", fontsize=14)\n",
    "ax[0, 0].set_xticklabels(['', ''], fontsize=14, rotation=90)\n",
    "ax[0, 0].set_yticklabels(['', ''], fontsize=14, rotation=360)\n",
    "\n",
    "sns.heatmap(kneighbors_cf, ax=ax[0][1], annot=True, cmap=plt.cm.copper)\n",
    "ax[0][1].set_title(\"KNearsNeighbors \\n Confusion Matrix\", fontsize=14)\n",
    "ax[0][1].set_xticklabels(['', ''], fontsize=14, rotation=90)\n",
    "ax[0][1].set_yticklabels(['', ''], fontsize=14, rotation=360)\n",
    "\n",
    "sns.heatmap(svc_cf, ax=ax[1][0], annot=True, cmap=plt.cm.copper)\n",
    "ax[1][0].set_title(\"Suppor Vector Classifier \\n Confusion Matrix\", fontsize=14)\n",
    "ax[1][0].set_xticklabels(['', ''], fontsize=14, rotation=90)\n",
    "ax[1][0].set_yticklabels(['', ''], fontsize=14, rotation=360)\n",
    "\n",
    "sns.heatmap(tree_cf, ax=ax[1][1], annot=True, cmap=plt.cm.copper)\n",
    "ax[1][1].set_title(\"DecisionTree Classifier \\n Confusion Matrix\", fontsize=14)\n",
    "ax[1][1].set_xticklabels(['', ''], fontsize=14, rotation=90)\n",
    "ax[1][1].set_yticklabels(['', ''], fontsize=14, rotation=360)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c971ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f134b885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
